{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "54f0b7d7",
      "metadata": {},
      "source": [
        "# üçè Observability & Tracing Demo with `azure-ai-projects` and `azure-ai-inference` üçé\n",
        "\n",
        "Welcome to this **Health & Fitness**-themed notebook, where we'll explore how to set up **observability** and **tracing** for:\n",
        "\n",
        "1. **Basic LLM calls** using an `AIProjectClient`.\n",
        "2. **Multi-step** interactions using an **Agent** (such as a Health Resource Agent).\n",
        "3. **Tracing** your local usage in **console** (stdout) or via an **OTLP endpoint** (like **Prompty** or **Aspire**).\n",
        "4. Sending those **traces** to **Azure Monitor** (Application Insights) so you can view them in **Azure AI Foundry**.\n",
        "\n",
        "> **Disclaimer**: This is a fun demonstration of AI and observability! Any references to workouts, diets, or health routines in the code or prompts are purely for **educational** purposes. Always consult a professional for health advice.\n",
        "\n",
        "## Contents\n",
        "1. **Initialization**: Setting up environment, creating clients.\n",
        "2. **Basic LLM Call**: Quick demonstration of retrieving model completions.\n",
        "3. **Connections**: Listing project connections.\n",
        "4. **Observability & Tracing**\n",
        "   - **Console / Local** tracing\n",
        "   - **Prompty / Aspire**: piping traces to a local OTLP endpoint\n",
        "   - **Azure Monitor** tracing: hooking up to Application Insights\n",
        "   - **Verifying** your traces in Azure AI Foundry\n",
        "5. **Agent-based Example**:\n",
        "   - Creating a simple \"Health Resource Agent\" referencing sample docs.\n",
        "   - Multi-turn conversation with tracing.\n",
        "   - Cleanup.\n",
        "\n",
        "<img src=\"./seq-diagrams/1-observability.png\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e13f9f3",
      "metadata": {},
      "source": [
        "## 1. Initialization & Setup\n",
        "**Prerequisites**:\n",
        "- A `.env` file containing `PROJECT_CONNECTION_STRING` (and optionally `MODEL_DEPLOYMENT_NAME`).\n",
        "- Roles/permissions in Azure AI Foundry that let you do inference & agent creation.\n",
        "- A local environment with `azure-ai-projects`, `azure-ai-inference`, `opentelemetry` packages installed.\n",
        "\n",
        "**What we do**:\n",
        "- Load environment variables.\n",
        "- Initialize `AIProjectClient`.\n",
        "- Check that we can talk to a model (like `gpt-4o`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d1ccdace",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found cred.json at: d:\\MLOps\\Gen Ai & MLOps Masterclass\\Materilas\\test\\ai-foundry-workshop\\cred.json\n",
            "‚úÖ Successfully created AIProjectClient!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.inference.models import UserMessage, CompletionsFinishReason\n",
        "\n",
        "def find_cred_json(start_path):\n",
        "    # Start from current directory and go up\n",
        "    current = Path(start_path)\n",
        "    while current != current.parent:  # while we haven't hit the root\n",
        "        cred_file = current / 'cred.json'\n",
        "        if cred_file.exists():\n",
        "            return str(cred_file)\n",
        "        current = current.parent\n",
        "    return None\n",
        "\n",
        "try:\n",
        "    # Search in the parent directory and its subdirectories\n",
        "    parent_dir = os.path.dirname(os.getcwd())  # Get parent directory\n",
        "    file_path = find_cred_json(parent_dir)\n",
        "\n",
        "    if not file_path:\n",
        "        raise FileNotFoundError(\"cred.json not found in parent directories\")\n",
        "\n",
        "    print(f\"Found cred.json at: {file_path}\")\n",
        "\n",
        "    # Load and parse the JSON file\n",
        "    with open(file_path, 'r') as f:\n",
        "        loaded_config = json.load(f)\n",
        "\n",
        "    connection_string = loaded_config.get(\"PROJECT_CONNECTION_STRING\")\n",
        "    if not connection_string:\n",
        "        raise ValueError(\"üö® PROJECT_CONNECTION_STRING not set in .env.\")\n",
        "\n",
        "# Initialize AIProjectClient\n",
        "\n",
        "    project_client = AIProjectClient.from_connection_string(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        conn_str=connection_string\n",
        "    )\n",
        "    print(\"‚úÖ Successfully created AIProjectClient!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating AIProjectClient: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e24461b",
      "metadata": {},
      "source": [
        "## 2. Basic LLM Call\n",
        "We'll do a **quick** chat completion request to confirm everything is working. We'll ask a simple question: \"How many feet are in a mile?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d7fcdaba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üí°Response:\n",
            "There are **5,280 feet** in a mile.\n",
            "\n",
            "Finish reason: CompletionsFinishReason.STOPPED\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Create a ChatCompletions client\n",
        "    inference_client = project_client.inference.get_chat_completions_client()\n",
        "    # Default to \"gpt-4o\" if no env var is set\n",
        "    model_name = os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
        "\n",
        "    user_question = \"How many feet are in a mile?\"\n",
        "    response = inference_client.complete(\n",
        "        model=model_name,\n",
        "        messages=[UserMessage(content=user_question)]\n",
        "    )\n",
        "    print(\"\\nüí°Response:\")\n",
        "    print(response.choices[0].message.content)\n",
        "    print(\"\\nFinish reason:\", response.choices[0].finish_reason)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Could not complete the chat request:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b83517e",
      "metadata": {},
      "source": [
        "## 3. List & Inspect Connections\n",
        "Check out the **connections** your project has: these might be Azure OpenAI or other resource attachments. We'll just list them here for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b70793c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîé Found 6 total connections.\n",
            "1) Name: ai-sarath8096ai755387175201_aoai, Type: ConnectionType.AZURE_OPEN_AI, Endpoint: https://ai-sarath8096ai755387175201.openai.azure.com\n",
            "2) Name: ai-sarath8096ai755387175201, Type: ConnectionType.AZURE_AI_SERVICES, Endpoint: https://ai-sarath8096ai755387175201.cognitiveservices.azure.com\n",
            "3) Name: groundingwithbing, Type: ApiKey, Endpoint: https://api.bing.microsoft.com\n",
            "4) Name: psitronaiserach, Type: ConnectionType.AZURE_AI_SEARCH, Endpoint: https://psitronaiserach.search.windows.net\n",
            "5) Name: sarath-1178/workspaceartifactstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://stsarath8096755387175201.core.windows.net/c5b9c0f7-896b-482f-87e3-30d1d0c79dbf-azureml\n",
            "6) Name: sarath-1178/workspaceblobstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://stsarath8096755387175201.core.windows.net/c5b9c0f7-896b-482f-87e3-30d1d0c79dbf-azureml-blobstore\n",
            "\n",
            "üåÄ Found 1 Azure OpenAI connections:\n",
            "   -> ai-sarath8096ai755387175201_aoai\n",
            "\n",
            "‚≠ê Default Azure AI Services connection:\n",
            "{\n",
            " \"name\": \"ai-sarath8096ai755387175201\",\n",
            " \"id\": \"/subscriptions/1c2fd79b-ad21-4ad0-8d53-12de16650452/resourceGroups/rg-sarath-1834_ai/providers/Microsoft.MachineLearningServices/workspaces/sarath-1178/connections/ai-sarath8096ai755387175201\",\n",
            " \"authentication_type\": \"ApiKey\",\n",
            " \"connection_type\": \"ConnectionType.AZURE_AI_SERVICES\",\n",
            " \"endpoint_url\": \"https://ai-sarath8096ai755387175201.cognitiveservices.azure.com\",\n",
            " \"key\": null\n",
            " \"token_credential\": null\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.projects.models import ConnectionType\n",
        "\n",
        "all_conns = project_client.connections.list()\n",
        "print(f\"üîé Found {len(all_conns)} total connections.\")\n",
        "for idx, c in enumerate(all_conns):\n",
        "    print(f\"{idx+1}) Name: {c.name}, Type: {c.connection_type}, Endpoint: {c.endpoint_url}\")\n",
        "\n",
        "# Filter for Azure OpenAI connections\n",
        "aoai_conns = project_client.connections.list(connection_type=ConnectionType.AZURE_OPEN_AI)\n",
        "print(f\"\\nüåÄ Found {len(aoai_conns)} Azure OpenAI connections:\")\n",
        "for c in aoai_conns:\n",
        "    print(f\"   -> {c.name}\")\n",
        "\n",
        "# Get default connection of type AZURE_AI_SERVICES\n",
        "default_conn = project_client.connections.get_default(connection_type=ConnectionType.AZURE_AI_SERVICES,\n",
        "                                                     include_credentials=False)\n",
        "if default_conn:\n",
        "    print(\"\\n‚≠ê Default Azure AI Services connection:\")\n",
        "    print(default_conn)\n",
        "else:\n",
        "    print(\"No default connection found for Azure AI Services.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce0c8f7",
      "metadata": {},
      "source": [
        "# 4. Observability & Tracing\n",
        "\n",
        "We want to **collect telemetry** from our LLM calls, for example:\n",
        "- Timestamps of requests.\n",
        "- Latency.\n",
        "- Potential errors.\n",
        "- Optionally, the actual prompts & responses (if you enable content recording).\n",
        "\n",
        "We'll show how to set up:\n",
        "1. **Console** or local OTLP endpoint instrumentation.\n",
        "2. **Azure Monitor** instrumentation with Application Insights.\n",
        "3. **Viewing** your traces in Azure AI Foundry's portal.\n",
        "\n",
        "## 4.1 Local Console Debugging\n",
        "We'll install instrumentation packages and enable them. Then we'll do a quick chat call to see if logs appear in **stdout**.\n",
        "\n",
        "**Note**: If you want to see more advanced local dashboards, you can:\n",
        "- Use [Prompty](https://github.com/microsoft/prompty).\n",
        "- Use [Aspire Dashboard](https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/standalone?tabs=bash) to visualize your OTLP traces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "16d366bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opentelemetry-instrumentation-openai-v2\n",
            "  Downloading opentelemetry_instrumentation_openai_v2-2.1b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc in c:\\python312\\lib\\site-packages (1.27.0)\n",
            "Collecting opentelemetry-api~=1.28 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-instrumentation~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc) (1.2.14)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc) (1.65.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in c:\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc) (1.66.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.27.0 in c:\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc) (1.27.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in c:\\python312\\lib\\site-packages (from opentelemetry-proto==1.27.0->opentelemetry-exporter-otlp-proto-grpc) (4.25.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\python312\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-grpc) (1.16.0)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\python312\\lib\\site-packages (from opentelemetry-api~=1.28->opentelemetry-instrumentation-openai-v2) (7.2.1)\n",
            "Requirement already satisfied: packaging>=18.0 in c:\\python312\\lib\\site-packages (from opentelemetry-instrumentation~=0.49b0->opentelemetry-instrumentation-openai-v2) (24.1)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-api~=1.28 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-api~=1.28 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-api~=1.28 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-instrumentation~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-api~=1.28 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk~=1.30.0 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\python312\\lib\\site-packages (from opentelemetry-sdk~=1.30.0->opentelemetry-exporter-otlp-proto-grpc) (4.12.2)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\python312\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.28->opentelemetry-instrumentation-openai-v2) (3.20.0)\n",
            "Downloading opentelemetry_instrumentation_openai_v2-2.1b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Installing collected packages: protobuf, opentelemetry-proto, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-openai-v2, opentelemetry-exporter-otlp-proto-grpc\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.4\n",
            "    Uninstalling protobuf-4.25.4:\n",
            "      Successfully uninstalled protobuf-4.25.4\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.27.0\n",
            "    Uninstalling opentelemetry-proto-1.27.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.27.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.27.0\n",
            "    Uninstalling opentelemetry-api-1.27.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.27.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.48b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.48b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.48b0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.27.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.27.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.27.0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.27.0\n",
            "    Uninstalling opentelemetry-sdk-1.27.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.27.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.27.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.27.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.27.0\n",
            "Successfully installed opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-openai-v2-2.1b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 protobuf-5.29.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "feast 0.40.1 requires protobuf<5.0.0,>=4.24.0, but you have protobuf 5.29.3 which is incompatible.\n",
            "opentelemetry-exporter-otlp 1.27.0 requires opentelemetry-exporter-otlp-proto-grpc==1.27.0, but you have opentelemetry-exporter-otlp-proto-grpc 1.30.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.27.0 requires opentelemetry-exporter-otlp-proto-common==1.27.0, but you have opentelemetry-exporter-otlp-proto-common 1.30.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.27.0 requires opentelemetry-proto==1.27.0, but you have opentelemetry-proto 1.30.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.27.0 requires opentelemetry-sdk~=1.27.0, but you have opentelemetry-sdk 1.30.0 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: C:\\Python312\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# You only need to install these once.\n",
        "!pip install opentelemetry-instrumentation-openai-v2 opentelemetry-exporter-otlp-proto-grpc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4767143a",
      "metadata": {},
      "source": [
        "### 4.1.1 Enable OpenTelemetry for Azure AI Inference\n",
        "We set environment variables to ensure:\n",
        "1. **Prompt content** is captured (optional!)\n",
        "2. The **Azure SDK** uses OpenTelemetry as its tracing implementation.\n",
        "3. We call `AIInferenceInstrumentor().instrument()` to patch and enable the instrumentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ef06776",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Azure AI Inference instrumentation enabled.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
        "\n",
        "# (Optional) capture prompt & completion contents in traces\n",
        "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"  # or 'false'\n",
        "\n",
        "# Let the Azure SDK know we want to use OpenTelemetry\n",
        "os.environ[\"AZURE_SDK_TRACING_IMPLEMENTATION\"] = \"opentelemetry\"\n",
        "\n",
        "# Instrument the Azure AI Inference client library\n",
        "AIInferenceInstrumentor().instrument()\n",
        "print(\"‚úÖ Azure AI Inference instrumentation enabled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "480fbc30",
      "metadata": {},
      "source": [
        "### 4.1.2 Point Traces to Console or Local OTLP\n",
        "The simplest is to pipe them to **stdout**. If you want to send them to **Prompty** or **Aspire**, specify the local OTLP endpoint URL (usually `\"http://localhost:4317\"` or similar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d202f67d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not call `OpenAIInstrumentor().instrument()` since `opentelemetry-instrumentation-openai-v2` is not installed\n",
            "Could not call LangchainInstrumentor().instrument()` since `opentelemetry-instrumentation-langchain` is not installed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ Response: A simple 5-minute warmup routine can help prep your body for exercise, increase blood flow to muscles, and reduce the risk of injury. Here‚Äôs a full-body, dynamic warmup that‚Äôs quick and effective:\n",
            "\n",
            "### **1. Arm Circles (30 seconds)**\n",
            "- Extend your arms to the sides at shoulder height.\n",
            "- Make small forward circles for 15 seconds, then reverse for 15 seconds.\n",
            "\n",
            "### **2. High Knees (30 seconds)**\n",
            "- Jog in place, bringing your knees up high, as close to your chest as possible.\n",
            "- Pump your arms as you move.\n",
            "\n",
            "### **3. Shoulder Rolls (30 seconds)**\n",
            "- Roll your shoulders slowly forward for 15 seconds, then backward for 15 seconds.\n",
            "\n",
            "### **4. Bodyweight Squats (1 minute)**\n",
            "- Stand with feet shoulder-width apart.\n",
            "- Lower into a squat position, keeping your chest up and knees behind your toes.\n",
            "- Slowly rise back to standing and repeat.\n",
            "\n",
            "### **5. Dynamic Lunges with a Twist (1 minute)**\n",
            "- Step your right foot forward into a lunge while keeping your chest up.\n",
            "- Twist your torso to the right side, then return to center and rise back up.\n",
            "- Repeat with the left leg, alternating sides.\n",
            "\n",
            "### **6. Jumping Jacks (30 seconds)**\n",
            "- Jump your feet out while raising your arms overhead.\n",
            "- Jump back to your starting position and repeat.\n",
            "\n",
            "### **7. Cat-Cow Stretch (30 seconds)**\n",
            "- Get on hands and knees in a tabletop position.\n",
            "- Inhale as you arch your back, looking up (Cow).\n",
            "- Exhale as you round your back, tucking your chin and pelvis (Cat).\n",
            "\n",
            "By combining cardio, dynamic stretches, and light body-weight movements, this quick routine will get your muscles warm and ready for more intense activity!\n"
          ]
        }
      ],
      "source": [
        "project_client.telemetry.enable(destination=sys.stdout)\n",
        "# Or, to send to a local OTLP collector (Prompty/Aspire), do:\n",
        "#   project_client.telemetry.enable(destination=\"http://localhost:4317\")\n",
        "\n",
        "try:\n",
        "    local_client = project_client.inference.get_chat_completions_client()\n",
        "    user_prompt = \"What's a simple 5-minute warmup routine?\"\n",
        "    local_resp = local_client.complete(\n",
        "        model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
        "        messages=[UserMessage(content=user_prompt)]\n",
        "    )\n",
        "    print(\"\\nü§ñ Response:\", local_resp.choices[0].message.content)\n",
        "except Exception as exc:\n",
        "    print(f\"‚ùå Error in local-tracing example: {exc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3c0fdd4",
      "metadata": {},
      "source": [
        "## 4.2 Azure Monitor Tracing (Application Insights)\n",
        "Now we'll set up tracing to **Application Insights**, which will forward your logs to the **Azure AI Foundry** **Tracing** page.\n",
        "\n",
        "**Steps**:\n",
        "1. In AI Foundry, go to your project‚Äôs **Tracing** tab, attach (or create) an **Application Insights** resource.\n",
        "2. In code, call `project_client.telemetry.get_connection_string()` to retrieve the instrumentation key.\n",
        "3. Use `azure.monitor.opentelemetry.configure_azure_monitor(...)` with that connection.\n",
        "4. Make an inference call -> logs appear in the Foundry portal (and in Azure Monitor itself).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0207221c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\MLOps\\Gen Ai & MLOps Masterclass\\Materilas\\test\\ai-foundry-workshop\\.venv\\Scripts\\python.exe: No module named pip\n"
          ]
        }
      ],
      "source": [
        "%pip install azure-monitor-opentelemetry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "552014a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Found App Insights connection string, configuring...\n",
            "\n",
            "ü§ñ Response (logged to App Insights):\n",
            "Absolutely! Here are some simple and effective at-home cardio exercises that don't require equipment and can be done in small spaces:\n",
            "\n",
            "### 1. **Jumping Jacks**\n",
            "   - Classic and effective, jumping jacks get your heart rate up quickly.\n",
            "   - How to: Jump your feet out to the sides while raising your arms overhead, then jump back to the starting position.\n",
            "   - Duration: Try 3 sets of 30‚Äì60 seconds.\n",
            "\n",
            "### 2. **High Knees**\n",
            "   - A great way to increase your heart rate and engage your core.\n",
            "   - How to: Jog in place, bringing your knees up as high as possible (aim for waist height) and pumping your arms.\n",
            "   - Duration: 3 sets of 30‚Äì60 seconds.\n",
            "\n",
            "### 3. **Mountain Climbers**\n",
            "   - This full-body exercise combines cardio with core strengthening.\n",
            "   - How to: Start in a plank position and alternate bringing your knees toward your chest as quickly as possible.\n",
            "   - Duration: 3 sets of 20‚Äì30 seconds.\n",
            "\n",
            "### 4. **Burpees**\n",
            "   - A total-body, high-intensity exercise.\n",
            "   - How to: Drop into a squat, place your hands on the ground, jump or step your feet back into a plank, do a push-up (optional), then jump your feet back to your hands and leap up.\n",
            "   - Duration: 3 sets of 8‚Äì12 reps.\n",
            "\n",
            "### 5. **Jogging in Place**\n",
            "   - A super-simple way to get moving and elevate your heart rate.\n",
            "   - How to: Jog softly in place, lifting your knees slightly and swinging your arms.\n",
            "   - Duration: 3‚Äì5 minutes straight or in intervals.\n",
            "\n",
            "### 6. **Invisible Jump Rope**\n",
            "   - Jumping without an actual rope mimics the benefits of jumping rope but is easier to do almost anywhere.\n",
            "   - How to: Pretend you're holding a jump rope and hop on the balls of your feet, keeping your knees soft.\n",
            "   - Duration: 3 sets of 30‚Äì60 seconds.\n",
            "\n",
            "### 7. **Stair Climbing (Optional)**\n",
            "   - If you have stairs at home, this is a fantastic cardio option.\n",
            "   - How to: Walk, jog, or run up and down your stairs at a pace you can handle.\n",
            "   - Duration: 5‚Äì10 minutes (rest as needed).\n",
            "\n",
            "### 8. **Dancing**\n",
            "   - Put on your favorite upbeat music and let loose‚Äîit‚Äôs a fun way to burn calories and improve your mood.\n",
            "   - How to: Freestyle dance or follow along to an online dance workout.\n",
            "   - Duration: 15‚Äì30 minutes.\n",
            "\n",
            "### 9. **Skater Jumps**\n",
            "   - A great exercise for cardio and lateral movement.\n",
            "   - How to: Jump laterally to one side, landing softly on one foot while sweeping your other foot behind you. Then jump to the other side.\n",
            "   - Duration: 3 sets of 20‚Äì30 seconds.\n",
            "\n",
            "### 10. **Plank Jacks**\n",
            "   - Combines the core-strengthening power of a plank with a cardio boost.\n",
            "   - How to: Get into a plank position and jump your feet out wide and back together, like a horizontal jumping jack.\n",
            "   - Duration: 3 sets of 20‚Äì30 seconds.\n",
            "\n",
            "---\n",
            "\n",
            "### Tips for Success:\n",
            "- **Warm Up:** Do light stretches or 2‚Äì3 minutes of low-intensity movements (like marching in place) before starting.\n",
            "- **Modify as Needed:** Adjust intensity to match your fitness level.\n",
            "- **Cool Down:** End with stretching to prevent soreness and improve flexibility.\n",
            "\n",
            "Pick 2‚Äì4 exercises and perform them in intervals (e.g., 30 seconds of work, 15 seconds of rest) for a quick circuit workout. Enjoy getting your heart pumping!\n"
          ]
        }
      ],
      "source": [
        "from azure.monitor.opentelemetry import configure_azure_monitor\n",
        "from azure.ai.inference.models import UserMessage\n",
        "\n",
        "app_insights_conn_str = project_client.telemetry.get_connection_string()\n",
        "if app_insights_conn_str:\n",
        "    print(\"üîß Found App Insights connection string, configuring...\")\n",
        "    configure_azure_monitor(connection_string=app_insights_conn_str)\n",
        "    # Optionally add more instrumentation (for openai or langchain):\n",
        "    project_client.telemetry.enable()\n",
        "    \n",
        "    # Let's do a test call that logs to AI Foundry's Tracing page\n",
        "    try:\n",
        "        with project_client.inference.get_chat_completions_client() as client:\n",
        "            prompt_msg = \"Any easy at-home cardio exercise recommendations?\"\n",
        "            response = client.complete(\n",
        "                model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
        "                messages=[UserMessage(content=prompt_msg)]\n",
        "            )\n",
        "            print(\"\\nü§ñ Response (logged to App Insights):\")\n",
        "            print(response.choices[0].message.content)\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Chat completions with Azure Monitor example failed:\", e)\n",
        "else:\n",
        "    print(\"No Application Insights connection string is configured in this project.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4991833",
      "metadata": {},
      "source": [
        "### 4.3 Viewing Traces in Azure AI Foundry\n",
        "After running the above code:\n",
        "1. Go to your AI Foundry project.\n",
        "2. Click **Tracing** on the sidebar.\n",
        "3. You should see the logs from your calls.\n",
        "4. Filter, expand, or explore them as needed.\n",
        "\n",
        "Also, if you want more advanced dashboards, you can open your **Application Insights** resource from the Foundry. In the App Insights portal, you get additional features like **end-to-end transaction** details, query logs, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31dbb932",
      "metadata": {},
      "source": [
        "# 5. Agent-based Example\n",
        "We'll now create a **Health Resource Agent** that references sample docs about recipes or guidelines, then demonstrate:\n",
        "1. Creating an Agent with instructions.\n",
        "2. Creating a conversation thread.\n",
        "3. Running multi-step queries with **observability** enabled.\n",
        "4. Optionally cleaning up resources at the end.\n",
        "\n",
        "> The agent approach is helpful when you want more sophisticated conversation flows or **tool usage** (like file search)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "303ad934",
      "metadata": {},
      "source": [
        "## 5.1 Create Sample Files & Vector Store\n",
        "We'll create dummy `.md` files about recipes/guidelines, then push them into a **vector store** so our agent can do semantic search.\n",
        "\n",
        "(*This portion is a quick summary‚Äîsee [the other file-search tutorial] if you need more details.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1e09113d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Created sample resource files: recipes.md, guidelines.md\n",
            "‚úÖ Uploaded: recipes.md -> File ID: assistant-PzbkXbvjJpHaamegaCyBXo\n",
            "‚úÖ Uploaded: guidelines.md -> File ID: assistant-5fMXUXTZ7KmYzEcK5uUCqG\n",
            "üéâ Created vector store 'health_resources_example', ID: vs_RUG8NZczCkYqLdbLPriOAZxB\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.projects.models import (\n",
        "    FileSearchTool,\n",
        "    FilePurpose,\n",
        "    MessageTextContent,\n",
        "    MessageRole\n",
        ")\n",
        "\n",
        "def create_sample_files():\n",
        "    \"\"\"Create some local .md files with sample text.\"\"\"\n",
        "    recipes_md = (\n",
        "        \"\"\"# Healthy Recipes Database\\n\\n\"\n",
        "        \"## Gluten-Free Recipes\\n\"\n",
        "        \"1. Quinoa Bowl\\n\"\n",
        "        \"   - Ingredients: quinoa, vegetables, olive oil\\n\"\n",
        "        \"   - Instructions: Cook quinoa, add vegetables\\n\\n\"\n",
        "        \"2. Rice Pasta\\n\"\n",
        "        \"   - Ingredients: rice pasta, mixed vegetables\\n\"\n",
        "        \"   - Instructions: Boil pasta, saut√© vegetables\\n\\n\"\n",
        "        \"## Diabetic-Friendly Recipes\\n\"\n",
        "        \"1. Low-Carb Stir Fry\\n\"\n",
        "        \"   - Ingredients: chicken, vegetables, tamari sauce\\n\"\n",
        "        \"   - Instructions: Cook chicken, add vegetables\\n\\n\"\n",
        "        \"## Heart-Healthy Recipes\\n\"\n",
        "        \"1. Baked Salmon\\n\"\n",
        "        \"   - Ingredients: salmon, lemon, herbs\\n\"\n",
        "        \"   - Instructions: Season salmon, bake\\n\\n\"\n",
        "        \"2. Mediterranean Bowl\\n\"\n",
        "        \"   - Ingredients: chickpeas, vegetables, tahini\\n\"\n",
        "        \"   - Instructions: Combine ingredients\\n\"\"\"\n",
        "    )\n",
        "\n",
        "    guidelines_md = (\n",
        "        \"\"\"# Dietary Guidelines\\n\\n\"\n",
        "        \"## General Guidelines\\n\"\n",
        "        \"- Eat a variety of foods\\n\"\n",
        "        \"- Control portion sizes\\n\"\n",
        "        \"- Stay hydrated\\n\\n\"\n",
        "        \"## Special Diets\\n\"\n",
        "        \"1. Gluten-Free Diet\\n\"\n",
        "        \"   - Avoid wheat, barley, rye\\n\"\n",
        "        \"   - Focus on naturally gluten-free foods\\n\\n\"\n",
        "        \"2. Diabetic Diet\\n\"\n",
        "        \"   - Monitor carbohydrate intake\\n\"\n",
        "        \"   - Choose low glycemic foods\\n\\n\"\n",
        "        \"3. Heart-Healthy Diet\\n\"\n",
        "        \"   - Limit saturated fats\\n\"\n",
        "        \"   - Choose lean proteins\\n\"\"\"\n",
        "    )\n",
        "\n",
        "    with open(\"recipes.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(recipes_md)\n",
        "    with open(\"guidelines.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(guidelines_md)\n",
        "\n",
        "    print(\"üìÑ Created sample resource files: recipes.md, guidelines.md\")\n",
        "    return [\"recipes.md\", \"guidelines.md\"]\n",
        "\n",
        "sample_files = create_sample_files()\n",
        "\n",
        "def create_vector_store(files, store_name=\"my_health_resources\"):\n",
        "    try:\n",
        "        uploaded_ids = []\n",
        "        for fp in files:\n",
        "            upl = project_client.agents.upload_file_and_poll(\n",
        "                file_path=fp,\n",
        "                purpose=FilePurpose.AGENTS  # Add FilePurpose.AGENTS here\n",
        "            )\n",
        "            uploaded_ids.append(upl.id)\n",
        "            print(f\"‚úÖ Uploaded: {fp} -> File ID: {upl.id}\")\n",
        "\n",
        "        # Create vector store from these file IDs\n",
        "        vs = project_client.agents.create_vector_store_and_poll(\n",
        "            file_ids=uploaded_ids,\n",
        "            name=store_name\n",
        "        )\n",
        "        print(f\"üéâ Created vector store '{store_name}', ID: {vs.id}\")\n",
        "        return vs, uploaded_ids\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating vector store: {e}\")\n",
        "        return None, []\n",
        "\n",
        "vector_store, file_ids = None, []\n",
        "if sample_files:\n",
        "    vector_store, file_ids = create_vector_store(sample_files, store_name=\"health_resources_example\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "145eb186",
      "metadata": {},
      "source": [
        "## 5.2 Create a Health Resource Agent\n",
        "We'll create a **FileSearchTool** referencing the vector store, then create an agent with instructions that it should:\n",
        "1. Provide disclaimers.\n",
        "2. Offer general nutrition or recipe tips.\n",
        "3. Cite sources if possible.\n",
        "4. Encourage professional consultation for deeper medical advice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7f604175",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéâ Created agent 'health-search-agent' with ID: asst_IXtve8P4QDehmctjuGCXaFah\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.projects.models import FileSearchTool, FilePurpose\n",
        "from azure.ai.projects.models import ConnectionType, MessageTextContent, MessageRole\n",
        "\n",
        "def create_health_agent(vs_id):\n",
        "    try:\n",
        "        # The tool references our vector store so the agent can search it\n",
        "        file_search_tool = FileSearchTool(vector_store_ids=[vs_id])\n",
        "        \n",
        "        instructions = \"\"\"\n",
        "            You are a health resource advisor with access to dietary and recipe files.\n",
        "            You:\n",
        "            1. Always present disclaimers (you're not a medical professional)\n",
        "            2. Provide references to files when possible\n",
        "            3. Focus on general nutrition or recipe tips.\n",
        "            4. Encourage professional consultation for more detailed advice.\n",
        "        \"\"\"\n",
        "\n",
        "        agent = project_client.agents.create_agent(\n",
        "            model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
        "            name=\"health-search-agent\",\n",
        "            instructions=instructions,\n",
        "            tools=file_search_tool.definitions,\n",
        "            tool_resources=file_search_tool.resources\n",
        "        )\n",
        "        print(f\"üéâ Created agent '{agent.name}' with ID: {agent.id}\")\n",
        "        return agent\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating health agent: {e}\")\n",
        "        return None\n",
        "\n",
        "health_agent = None\n",
        "if vector_store:\n",
        "    health_agent = create_health_agent(vector_store.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6995a6",
      "metadata": {},
      "source": [
        "## 5.3 Using the Agent\n",
        "Let's create a new conversation **thread** and ask the agent some questions. We'll rely on the **observability** settings we already configured so each step is traced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "86e5b4f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Created new thread, ID: thread_9HnPVs4o1eZK2d70AKJePE4q\n",
            "User asked: 'Could you suggest a gluten-free lunch recipe?'\n",
            "Run finished with status: RunStatus.COMPLETED\n",
            "User asked: 'Show me some heart-healthy meal ideas.'\n",
            "Run finished with status: RunStatus.COMPLETED\n",
            "User asked: 'What guidelines do you have for someone with diabetes?'\n",
            "Run finished with status: RunStatus.COMPLETED\n"
          ]
        }
      ],
      "source": [
        "def create_thread():\n",
        "    try:\n",
        "        thread = project_client.agents.create_thread()\n",
        "        print(f\"üìù Created new thread, ID: {thread.id}\")\n",
        "        return thread\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not create thread: {e}\")\n",
        "        return None\n",
        "\n",
        "def ask_question(thread_id, agent_id, user_question):\n",
        "    try:\n",
        "        # 1) Add user message\n",
        "        msg = project_client.agents.create_message(\n",
        "            thread_id=thread_id,\n",
        "            role=\"user\",\n",
        "            content=user_question\n",
        "        )\n",
        "        print(f\"User asked: '{user_question}'\")\n",
        "        # 2) Create & process a run\n",
        "        run = project_client.agents.create_and_process_run(\n",
        "            thread_id=thread_id,\n",
        "            assistant_id=agent_id\n",
        "        )\n",
        "        print(f\"Run finished with status: {run.status}\")\n",
        "        if run.last_error:\n",
        "            print(\"Error details:\", run.last_error)\n",
        "        return run\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error asking question: {e}\")\n",
        "        return None\n",
        "\n",
        "if health_agent:\n",
        "    thread = create_thread()\n",
        "    if thread:\n",
        "        # Let's ask a few sample questions\n",
        "        queries = [\n",
        "            \"Could you suggest a gluten-free lunch recipe?\",\n",
        "            \"Show me some heart-healthy meal ideas.\",\n",
        "            \"What guidelines do you have for someone with diabetes?\"\n",
        "        ]\n",
        "        for q in queries:\n",
        "            ask_question(thread.id, health_agent.id, q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c61d8d",
      "metadata": {},
      "source": [
        "### 5.3.1 Viewing the conversation\n",
        "We can retrieve the conversation messages to see how the agent responded, check if it cited file passages, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a1c57935",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üó£Ô∏è Conversation:\n",
            "[USER]: Could you suggest a gluten-free lunch recipe?\n",
            "\n",
            "[ASSISTANT]: Here's a simple gluten-free lunch recipe based on the files:\n",
            "\n",
            "**Quinoa Bowl**  \n",
            "- **Ingredients**: Quinoa, vegetables of choice, olive oil  \n",
            "- **Instructions**: Cook the quinoa according to package instructions. Add your favorite cooked or raw vegetables and drizzle with olive oil for added flavor„Äê4:1‚Ä†source„Äë.\n",
            "\n",
            "Feel free to adjust the ingredients according to your taste and add protein if needed!  \n",
            "*Disclaimer: I'm not a medical professional, so consult one for personalized dietary advice.*\n",
            "\n",
            "[USER]: Show me some heart-healthy meal ideas.\n",
            "\n",
            "[ASSISTANT]: Here are a couple of heart-healthy meal ideas:\n",
            "\n",
            "1. **Baked Salmon**  \n",
            "   - **Ingredients**: Salmon, lemon, herbs  \n",
            "   - **Instructions**: Season the salmon with lemon and herbs. Bake it in the oven until cooked through.  \n",
            "   \n",
            "2. **Mediterranean Bowl**  \n",
            "   - **Ingredients**: Chickpeas, vegetables of your choice, tahini  \n",
            "   - **Instructions**: Combine the chickpeas with your favorite fresh or roasted vegetables. Drizzle with tahini for added flavor„Äê8:0‚Ä†source„Äë.\n",
            "\n",
            "These meals emphasize lean proteins and healthy fats, supporting cardiovascular health. *Reminder: Consult a healthcare provider or nutritionist for personalized guidance.*\n",
            "\n",
            "[USER]: What guidelines do you have for someone with diabetes?\n",
            "\n",
            "[ASSISTANT]: For managing diabetes through diet, here are some key guidelines from the files:\n",
            "\n",
            "1. **General Advice**:\n",
            "   - Monitor carbohydrate intake carefully.\n",
            "   - Opt for foods with a low glycemic index, which have a slower impact on blood sugar levels„Äê12:0‚Ä†source„Äë.\n",
            "\n",
            "2. **Recipe Example**:  \n",
            "   - **Low-Carb Stir Fry**  \n",
            "     - Ingredients: Chicken, vegetables, tamari sauce  \n",
            "     - Instructions: Cook chicken, add vegetables, and stir in tamari sauce„Äê12:1‚Ä†source„Äë.\n",
            "\n",
            "Maintaining balanced meals and portion control is essential. For thorough and personalized guidance, consult a healthcare provider or dietitian.\n",
            "\n",
            "\n",
            "üìé Checking for citations...\n",
            "- Citation snippet: '„Äê12:0‚Ä†source„Äë' from file ID: assistant-5fMXUXTZ7KmYzEcK5uUCqG\n",
            "- Citation snippet: '„Äê12:1‚Ä†source„Äë' from file ID: assistant-PzbkXbvjJpHaamegaCyBXo\n",
            "- Citation snippet: '„Äê8:0‚Ä†source„Äë' from file ID: assistant-PzbkXbvjJpHaamegaCyBXo\n",
            "- Citation snippet: '„Äê4:1‚Ä†source„Äë' from file ID: assistant-PzbkXbvjJpHaamegaCyBXo\n"
          ]
        }
      ],
      "source": [
        "def display_thread(thread_id):\n",
        "    try:\n",
        "        messages = project_client.agents.list_messages(thread_id=thread_id)\n",
        "        print(\"\\nüó£Ô∏è Conversation:\")\n",
        "        for m in reversed(messages.data):\n",
        "            if m.content:\n",
        "                last_content = m.content[-1]\n",
        "                if hasattr(last_content, \"text\"):\n",
        "                    print(f\"[{m.role.upper()}]: {last_content.text.value}\\n\")\n",
        "\n",
        "        print(\"\\nüìé Checking for citations...\")\n",
        "        for c in messages.file_citation_annotations:\n",
        "            print(f\"- Citation snippet: '{c.text}' from file ID: {c.file_citation['file_id']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not display thread: {e}\")\n",
        "\n",
        "# If we created a thread above, let's read it\n",
        "if health_agent and thread:\n",
        "    display_thread(thread.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7420c39",
      "metadata": {},
      "source": [
        "# 6. Cleanup\n",
        "If desired, we can remove the vector store, files, and agent to keep things tidy. (In a real solution, you might keep them around.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f473cddc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóëÔ∏è Deleted vector store.\n",
            "üóëÔ∏è Deleted uploaded files.\n",
            "üóëÔ∏è Deleted health agent.\n",
            "üóëÔ∏è Deleted local sample files.\n"
          ]
        }
      ],
      "source": [
        "def cleanup_resources():\n",
        "    try:\n",
        "        if 'vector_store' in globals() and vector_store:\n",
        "            project_client.agents.delete_vector_store(vector_store.id)\n",
        "            print(\"üóëÔ∏è Deleted vector store.\")\n",
        "\n",
        "        if 'file_ids' in globals() and file_ids:\n",
        "            for fid in file_ids:\n",
        "                project_client.agents.delete_file(fid)\n",
        "            print(\"üóëÔ∏è Deleted uploaded files.\")\n",
        "\n",
        "        if 'health_agent' in globals() and health_agent:\n",
        "            project_client.agents.delete_agent(health_agent.id)\n",
        "            print(\"üóëÔ∏è Deleted health agent.\")\n",
        "\n",
        "        if 'sample_files' in globals() and sample_files:\n",
        "            for sf in sample_files:\n",
        "                if os.path.exists(sf):\n",
        "                    os.remove(sf)\n",
        "            print(\"üóëÔ∏è Deleted local sample files.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error cleaning up: {e}\")\n",
        "\n",
        "\n",
        "cleanup_resources()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4956d0ec",
      "metadata": {},
      "source": [
        "# üéâ Wrap-Up\n",
        "We've demonstrated:\n",
        "1. **Basic LLM calls** with `AIProjectClient`.\n",
        "2. **Listing connections** in your Azure AI Foundry project.\n",
        "3. **Observability & tracing** in both local (console, OTLP endpoint) and cloud (App Insights) contexts.\n",
        "4. A quick **Agent** scenario that uses a vector store for searching sample docs.\n",
        "\n",
        "## Next Steps\n",
        "- Check the **Tracing** tab in your Azure AI Foundry portal to see the logs.\n",
        "- Explore advanced queries in Application Insights.\n",
        "- Use [Prompty](https://github.com/microsoft/prompty) or [Aspire](https://learn.microsoft.com/dotnet/aspire/) for local telemetry dashboards.\n",
        "- Incorporate this approach into your **production** GenAI pipelines!\n",
        "\n",
        "> üèãÔ∏è **Health Reminder**: The LLM's suggestions are for demonstration only. For real health decisions, consult a professional.\n",
        "\n",
        "Happy Observing & Tracing! üéâ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "name": "Observability_and_Tracing_Comprehensive"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
