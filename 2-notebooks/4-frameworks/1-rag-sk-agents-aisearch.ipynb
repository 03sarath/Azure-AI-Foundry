{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# 🏋️ Azure AI Search + Semantic Kernel + AI Agents: Fitness-Fun Workshop 🤸\n",
    "\n",
    "Welcome to this self-guided workshop where you'll:\n",
    "\n",
    "1. **Create** an Azure AI Search index containing some sample fitness equipment data\n",
    "2. **Upload** and verify your documents\n",
    "3. **Create** a Semantic Kernel Agent (powered by Azure AI Agent Service) that uses the Azure AI Search tool\n",
    "4. **Run** an asynchronous conversation to query your index (with a fun fitness twist)\n",
    "\n",
    "> **Note:** This demo uses Semantic Kernel’s abstractions over Azure AI Agents. Make sure you run:\n",
    ">\n",
    "> ```bash\n",
    "> pip install semantic-kernel[azure]\n",
    "> ```\n",
    "\n",
    "Also ensure you’ve set your environment variables for:\n",
    "\n",
    "- `PROJECT_CONNECTION_STRING`\n",
    "- `MODEL_DEPLOYMENT_NAME`\n",
    "\n",
    "Let’s get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prereq-md",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running the cells below, please verify:\n",
    "\n",
    "1. You have installed the required dependency:\n",
    "   ```bash\n",
    "   pip install semantic-kernel[azure]\n",
    "   ```\n",
    "2. Your environment is configured with the necessary variables (`PROJECT_CONNECTION_STRING` and `MODEL_DEPLOYMENT_NAME`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting semantic-kernel[azure]\n",
      "  Using cached semantic_kernel-1.22.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from semantic-kernel[azure]) (3.9.5)\n",
      "Collecting cloudevents~=1.0 (from semantic-kernel[azure])\n",
      "  Using cached cloudevents-1.11.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from semantic-kernel[azure]) (2.5.3)\n",
      "Collecting pydantic-settings~=2.0 (from semantic-kernel[azure])\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from semantic-kernel[azure]) (0.7.1)\n",
      "Requirement already satisfied: azure-identity~=1.13 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from semantic-kernel[azure]) (1.20.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from semantic-kernel[azure]) (1.26.4)\n",
      "Collecting openai~=1.61 (from semantic-kernel[azure])\n",
      "  Using cached openai-1.65.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting openapi_core<0.20,>=0.18 (from semantic-kernel[azure])\n",
      "  Using cached openapi_core-0.19.4-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting opentelemetry-api~=1.24 (from semantic-kernel[azure])\n",
      "  Using cached opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk~=1.24 (from semantic-kernel[azure])\n",
      "  Using cached opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting prance~=23.6.21.0 (from semantic-kernel[azure])\n",
      "  Using cached prance-23.6.21.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybars4~=0.9 (from semantic-kernel[azure])\n",
      "  Using cached pybars4-0.9.13-py3-none-any.whl\n",
      "Requirement already satisfied: jinja2~=3.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from semantic-kernel[azure]) (3.1.4)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from semantic-kernel[azure]) (1.6.0)\n",
      "Collecting scipy>=1.15.1 (from semantic-kernel[azure])\n",
      "  Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting azure-ai-inference>=1.0.0b6 (from semantic-kernel[azure])\n",
      "  Using cached azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting azure-ai-projects>=1.0.0b5 (from semantic-kernel[azure])\n",
      "  Using cached azure_ai_projects-1.0.0b6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting azure-core-tracing-opentelemetry>=1.0.0b11 (from semantic-kernel[azure])\n",
      "  Using cached azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting azure-search-documents>=11.6.0b4 (from semantic-kernel[azure])\n",
      "  Using cached azure_search_documents-11.6.0b9-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting azure-cosmos~=4.7 (from semantic-kernel[azure])\n",
      "  Using cached azure_cosmos-4.9.0-py3-none-any.whl.metadata (80 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel[azure]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel[azure]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel[azure]) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel[azure]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel[azure]) (1.9.3)\n",
      "Collecting isodate>=0.6.1 (from azure-ai-inference>=1.0.0b6->semantic-kernel[azure])\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from azure-ai-inference>=1.0.0b6->semantic-kernel[azure]) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from azure-ai-inference>=1.0.0b6->semantic-kernel[azure]) (4.11.0)\n",
      "Collecting typing-extensions>=4.6.0 (from azure-ai-inference>=1.0.0b6->semantic-kernel[azure])\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel[azure]) (42.0.5)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel[azure]) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel[azure]) (1.2.0)\n",
      "Collecting azure-common>=1.1 (from azure-search-documents>=11.6.0b4->semantic-kernel[azure])\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting deprecation<3.0,>=2.0 (from cloudevents~=1.0->semantic-kernel[azure])\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jinja2~=3.1->semantic-kernel[azure]) (2.1.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openai~=1.61->semantic-kernel[azure]) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openai~=1.61->semantic-kernel[azure]) (1.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai~=1.61->semantic-kernel[azure])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai~=1.61->semantic-kernel[azure])\n",
      "  Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openai~=1.61->semantic-kernel[azure]) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openai~=1.61->semantic-kernel[azure]) (4.66.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[azure]) (4.19.2)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel[azure])\n",
      "  Using cached jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[azure]) (10.1.0)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel[azure])\n",
      "  Using cached openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel[azure])\n",
      "  Using cached openapi_spec_validator-0.7.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel[azure])\n",
      "  Using cached parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[azure]) (3.0.3)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api~=1.24->semantic-kernel[azure])\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel[azure]) (7.0.1)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk~=1.24->semantic-kernel[azure])\n",
      "  Using cached opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel[azure]) (4.0.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel[azure]) (0.17.21)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel[azure]) (2.32.2)\n",
      "Requirement already satisfied: six~=1.15 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel[azure]) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel[azure]) (23.2)\n",
      "Collecting PyMeta3>=0.5.1 (from pybars4~=0.9->semantic-kernel[azure])\n",
      "  Using cached pymeta3-0.5.1-py3-none-any.whl\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel[azure]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel[azure]) (2.14.6)\n",
      "Collecting pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0 (from semantic-kernel[azure])\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pydantic-settings~=2.0->semantic-kernel[azure]) (0.21.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel[azure])\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai~=1.61->semantic-kernel[azure]) (3.7)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from cryptography>=2.5->azure-identity~=1.13->semantic-kernel[azure]) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel[azure]) (1.14.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.61->semantic-kernel[azure]) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai~=1.61->semantic-kernel[azure])\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.61->semantic-kernel[azure])\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel[azure]) (3.17.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel[azure]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel[azure]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel[azure]) (0.10.6)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel[azure]) (6.0.1)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel[azure])\n",
      "  Using cached pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity~=1.13->semantic-kernel[azure]) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel[azure]) (2.10.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel[azure]) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel[azure]) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel[azure]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel[azure]) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from tqdm>4->openai~=1.61->semantic-kernel[azure]) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity~=1.13->semantic-kernel[azure]) (2.21)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel[azure]) (305.1)\n",
      "Using cached azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
      "Using cached azure_ai_projects-1.0.0b6-py3-none-any.whl (187 kB)\n",
      "Using cached azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl (10 kB)\n",
      "Using cached azure_cosmos-4.9.0-py3-none-any.whl (303 kB)\n",
      "Using cached azure_search_documents-11.6.0b9-py3-none-any.whl (335 kB)\n",
      "Using cached cloudevents-1.11.0-py3-none-any.whl (55 kB)\n",
      "Using cached openai-1.65.1-py3-none-any.whl (472 kB)\n",
      "Using cached openapi_core-0.19.4-py3-none-any.whl (103 kB)\n",
      "Using cached opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Using cached opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Using cached prance-23.6.21.0-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.7 kB ? eta -:--:--\n",
      "   --------------------------------------  430.1/431.7 kB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 431.7/431.7 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.0 MB 40.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 31.4 MB/s eta 0:00:00\n",
      "Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "Using cached semantic_kernel-1.22.0-py3-none-any.whl (741 kB)\n",
      "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Using cached jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Using cached openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Using cached openapi_spec_validator-0.7.1-py3-none-any.whl (38 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Using cached pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: PyMeta3, parse, azure-common, typing-extensions, scipy, pybars4, pathable, jiter, isodate, h11, deprecation, deprecated, pydantic-core, prance, opentelemetry-api, jsonschema-path, httpcore, cloudevents, pydantic, opentelemetry-semantic-conventions, httpx, azure-search-documents, azure-cosmos, azure-core-tracing-opentelemetry, azure-ai-projects, azure-ai-inference, pydantic-settings, opentelemetry-sdk, openapi-schema-validator, openai, openapi-spec-validator, openapi_core, semantic-kernel\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed PyMeta3-0.5.1 azure-ai-inference-1.0.0b9 azure-ai-projects-1.0.0b6 azure-common-1.1.28 azure-core-tracing-opentelemetry-1.0.0b11 azure-cosmos-4.9.0 azure-search-documents-11.6.0b9 cloudevents-1.11.0 deprecated-1.2.18 deprecation-2.1.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 isodate-0.7.2 jiter-0.8.2 jsonschema-path-0.3.4 openai-1.65.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.1 openapi_core-0.19.4 opentelemetry-api-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 parse-1.20.2 pathable-0.4.4 prance-23.6.21.0 pybars4-0.9.13 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.8.1 scipy-1.15.2 semantic-kernel-1.22.0 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run the cell below if you have not installed the dependency yet\n",
    "!pip install semantic-kernel[azure]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "index-intro-md",
   "metadata": {},
   "source": [
    "## 1. Create & Populate Azure AI Search Index\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "1. **Create** an Azure AI Search index called `myfitnessindex` with a schema suited for fitness items\n",
    "2. **Upload** sample documents containing fitness equipment data\n",
    "3. **Verify** that the documents are searchable\n",
    "\n",
    "Make sure your environment has the appropriate search credentials (typically obtained via your AI Foundry project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87061bd4-7707-4818-84f4-bac04c3d8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cred.json at: D:\\MLOps\\Gen Ai & MLOps Masterclass\\Materilas\\test\\ai-foundry-workshop\\cred.json\n"
     ]
    }
   ],
   "source": [
    "# Import required Azure libraries\n",
    "import os\n",
    "import json  # For JSON operations\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_cred_json(start_path):\n",
    "    # Start from current directory and go up\n",
    "    current = Path(start_path)\n",
    "    while current != current.parent:  # while we haven't hit the root\n",
    "        cred_file = current / 'cred.json'\n",
    "        if cred_file.exists():\n",
    "            return str(cred_file)\n",
    "        current = current.parent\n",
    "    return None\n",
    "\n",
    "try:\n",
    "    # Search in the parent directory and its subdirectories\n",
    "    parent_dir = os.path.dirname(os.getcwd())  # Get parent directory\n",
    "    file_path = find_cred_json(parent_dir)\n",
    "\n",
    "    if not file_path:\n",
    "        raise FileNotFoundError(\"cred.json not found in parent directories\")\n",
    "\n",
    "    print(f\"Found cred.json at: {file_path}\")\n",
    "\n",
    "    # Load and parse the JSON file\n",
    "    with open(file_path, 'r') as f:\n",
    "        loaded_config = json.load(f)\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating search clients: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "init-search-clients",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Initialized AIProjectClient\n",
      "✅ Created SearchIndexClient\n",
      "✅ Created SearchClient for document operations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchFieldDataType, SearchableField\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "env_path = notebook_path.parent.parent / '.env'  # Adjust path as needed\n",
    "load_dotenv(env_path)\n",
    "\n",
    "connection_string = loaded_config.get(\"PROJECT_CONNECTION_STRING\")\n",
    "if not connection_string:\n",
    "    raise ValueError(\"🚨 PROJECT_CONNECTION_STRING not set in .env.\")\n",
    "\n",
    "# Initialize the AI Project client to access project resources\n",
    "try:\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        conn_str=connection_string\n",
    "    )\n",
    "    print(\"✅ Initialized AIProjectClient\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing AIProjectClient: {e}\")\n",
    "\n",
    "# Get the Azure AI Search connection details from the project (including endpoint and API key)\n",
    "search_conn = project_client.connections.get_default(\n",
    "    connection_type=ConnectionType.AZURE_AI_SEARCH,\n",
    "    include_credentials=True\n",
    ")\n",
    "\n",
    "if not search_conn:\n",
    "    raise RuntimeError(\"❌ No default Azure AI Search connection found in your project.\")\n",
    "\n",
    "# Define the index name for our fitness data\n",
    "index_name = \"myfitnessindex\"\n",
    "\n",
    "try:\n",
    "    credential = AzureKeyCredential(search_conn.key)\n",
    "    index_client = SearchIndexClient(endpoint=search_conn.endpoint_url, credential=credential)\n",
    "    print(\"✅ Created SearchIndexClient\")\n",
    "    \n",
    "    search_client = SearchClient(\n",
    "        endpoint=search_conn.endpoint_url,\n",
    "        index_name=index_name,\n",
    "        credential=credential\n",
    "    )\n",
    "    print(\"✅ Created SearchClient for document operations\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating search clients: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "schema-md",
   "metadata": {},
   "source": [
    "### Define the Index Schema\n",
    "\n",
    "We will create an index with the following fields:\n",
    "\n",
    "- `FitnessItemID`: Unique key\n",
    "- `Name`: Searchable text field (also filterable)\n",
    "- `Category`: Searchable, filterable, and facetable (e.g. Strength, Cardio, Flexibility)\n",
    "- `Price`: Numeric field (filterable, sortable, and facetable)\n",
    "- `Description`: Full-text searchable field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "create-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Deleted existing index: myfitnessindex\n",
      "🎉 Created index: myfitnessindex\n"
     ]
    }
   ],
   "source": [
    "def create_fitness_index():\n",
    "    fields = [\n",
    "        SimpleField(name=\"FitnessItemID\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"Name\", type=SearchFieldDataType.String, filterable=True),\n",
    "        SearchableField(name=\"Category\", type=SearchFieldDataType.String, filterable=True, facetable=True),\n",
    "        SimpleField(name=\"Price\", type=SearchFieldDataType.Double, filterable=True, sortable=True, facetable=True),\n",
    "        SearchableField(name=\"Description\", type=SearchFieldDataType.String)\n",
    "    ]\n",
    "\n",
    "    index = SearchIndex(name=index_name, fields=fields)\n",
    "\n",
    "    # Delete the index if it already exists (for a fresh start)\n",
    "    if index_name in [x.name for x in index_client.list_indexes()]:\n",
    "        index_client.delete_index(index_name)\n",
    "        print(f\"🗑️ Deleted existing index: {index_name}\")\n",
    "\n",
    "    created = index_client.create_index(index)\n",
    "    print(f\"🎉 Created index: {created.name}\")\n",
    "\n",
    "# Create the index\n",
    "create_fitness_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upload-docs-md",
   "metadata": {},
   "source": [
    "### Upload Sample Documents\n",
    "\n",
    "Now we’ll add some sample fitness items to `myfitnessindex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "upload-docs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Upload result: [<azure.search.documents._generated.models._models_py3.IndexingResult object at 0x0000022AEEDAB680>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x0000022AEEDD5610>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x0000022AEEDD4320>, <azure.search.documents._generated.models._models_py3.IndexingResult object at 0x0000022AEEDD5670>]\n",
      "✅ Documents uploaded to search index\n"
     ]
    }
   ],
   "source": [
    "def upload_fitness_docs():\n",
    "    search_client = SearchClient(\n",
    "        endpoint=search_conn.endpoint_url,\n",
    "        index_name=index_name,\n",
    "        credential=AzureKeyCredential(search_conn.key)\n",
    "    )\n",
    "\n",
    "    sample_docs = [\n",
    "        {\n",
    "            \"FitnessItemID\": \"1\",\n",
    "            \"Name\": \"Adjustable Dumbbell\",\n",
    "            \"Category\": \"Strength\",\n",
    "            \"Price\": 59.99,\n",
    "            \"Description\": \"A compact, adjustable weight for targeted muscle workouts.\"\n",
    "        },\n",
    "        {\n",
    "            \"FitnessItemID\": \"2\",\n",
    "            \"Name\": \"Yoga Mat\",\n",
    "            \"Category\": \"Flexibility\",\n",
    "            \"Price\": 25.0,\n",
    "            \"Description\": \"Non-slip mat designed for yoga, Pilates, and other exercises.\"\n",
    "        },\n",
    "        {\n",
    "            \"FitnessItemID\": \"3\",\n",
    "            \"Name\": \"Treadmill\",\n",
    "            \"Category\": \"Cardio\",\n",
    "            \"Price\": 499.0,\n",
    "            \"Description\": \"A sturdy treadmill with adjustable speed and incline settings.\"\n",
    "        },\n",
    "        {\n",
    "            \"FitnessItemID\": \"4\",\n",
    "            \"Name\": \"Resistance Bands\",\n",
    "            \"Category\": \"Strength\",\n",
    "            \"Price\": 15.0,\n",
    "            \"Description\": \"Set of colorful bands for light to moderate resistance workouts.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    result = search_client.upload_documents(documents=sample_docs)\n",
    "    print(f\"🚀 Upload result: {result}\")\n",
    "\n",
    "upload_fitness_docs()\n",
    "print(\"✅ Documents uploaded to search index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-md",
   "metadata": {},
   "source": [
    "### Verify the Documents\n",
    "\n",
    "Let’s perform a basic search query (e.g. for items in the **Strength** category) to ensure everything is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "verify-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Search results for 'Strength':\n",
      "--------------------------------------------------\n",
      "Name: Adjustable Dumbbell\n",
      "Category: Strength\n",
      "Price: $59.99\n",
      "Description: A compact, adjustable weight for targeted muscle workouts.\n",
      "--------------------------------------------------\n",
      "Name: Resistance Bands\n",
      "Category: Strength\n",
      "Price: $15.00\n",
      "Description: Set of colorful bands for light to moderate resistance workouts.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = search_client.search(search_text=\"Strength\", filter=None, top=10)\n",
    "\n",
    "print(\"🔍 Search results for 'Strength':\")\n",
    "print(\"-\" * 50)\n",
    "found_items = False\n",
    "for doc in results:\n",
    "    found_items = True\n",
    "    print(f\"Name: {doc['Name']}\")\n",
    "    print(f\"Category: {doc['Category']}\")\n",
    "    print(f\"Price: ${doc['Price']:.2f}\")\n",
    "    print(f\"Description: {doc['Description']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "if not found_items:\n",
    "    print(\"No matching items found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sk-agent-md",
   "metadata": {},
   "source": [
    "## 2. Create Semantic Kernel Agent with Azure AI Search Tool\n",
    "\n",
    "In this section we’ll use Semantic Kernel’s Azure AI Agent abstractions to build a fitness shopping assistant. This agent will:\n",
    "\n",
    "- Use your Azure OpenAI model (specified by `MODEL_DEPLOYMENT_NAME`)\n",
    "- Attach an **Azure AI Search tool** (pointing to `myfitnessindex`)\n",
    "- Engage in an asynchronous conversation that queries the index based on user input\n",
    "\n",
    "The code below uses asynchronous Python (with `asyncio`) and Semantic Kernel classes from the `semantic_kernel` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sk-agent-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Created thread with ID: thread_XiS5fwKIDDJwfz6jQe4fKrpK\n",
      "\n",
      "# User: Which items are best for strength training?\n",
      "\n",
      "# Agent: When it comes to strength training, there are various equipment and items that can be beneficial. Some popular items for strength training include:\n",
      "\n",
      "1. **Barbells**: Barbells are versatile and allow for a wide range of exercises to target different muscle groups.\n",
      "\n",
      "2. **Dumbbells**: Dumbbells are great for unilateral exercises and can be used to target specific muscles.\n",
      "\n",
      "3. **Kettlebells**: Kettlebells are excellent for functional and dynamic movements that engage multiple muscle groups.\n",
      "\n",
      "4. **Resistance Bands**: Resistance bands are portable and can be used for resistance training to increase strength and flexibility.\n",
      "\n",
      "5. **Weighted Medicine Balls**: Medicine balls are great for explosive movements and core strength exercises.\n",
      "\n",
      "6. **Weight Plates**: Weight plates can be used with barbells or on their own for various strength training exercises.\n",
      "\n",
      "7. **Suspension Trainers (e.g., TRX)**: Suspension trainers use body weight for resistance training and can help improve strength, balance, and flexibility.\n",
      "\n",
      "8. **Pull-Up Bar**: A pull-up bar is essential for upper body strength exercises like pull-ups and chin-ups.\n",
      "\n",
      "Remember, it's important to consult with a fitness professional or trainer to ensure proper form and technique when using these items for strength training. Also, please note that I am not providing medical advice.\n",
      "\n",
      "\n",
      "# User: I need something for cardio under $300. Any suggestions?\n",
      "\n",
      "# Agent: If you're looking for cardio equipment under $300, here are some budget-friendly options you might consider:\n",
      "\n",
      "1. **Jump Rope**: Jump ropes are affordable, portable, and great for cardiovascular workouts. They can improve coordination, agility, and endurance.\n",
      "\n",
      "2. **Stationary Exercise Bike**: There are basic models of stationary exercise bikes available within the $300 range. Look for simple designs that offer adjustable resistance levels.\n",
      "\n",
      "3. **Mini Stepper**: A mini stepper is a compact and affordable option for cardiovascular exercise. It simulates stair climbing and provides a good lower body workout.\n",
      "\n",
      "4. **Aerobic Step Platform**: An aerobic step platform can be used for aerobic exercises to elevate your heart rate and improve cardiovascular fitness. It's versatile and can be used for step-up exercises, cardio routines, and more.\n",
      "\n",
      "5. **Fitness DVDs or Online Classes**: Consider investing in fitness DVDs or subscribing to online workout platforms that offer a variety of cardio routines. This can be a cost-effective way to access guided workouts.\n",
      "\n",
      "Keep in mind that the effectiveness of your cardio workout also depends on your commitment and consistency. Choose an option that you enjoy and can stick with for long-term fitness goals. Additionally, please ensure that you consult with a fitness professional or healthcare provider before starting any new exercise routine. And remember, I am not providing medical advice.\n",
      "\n",
      "🗑️ Cleaned up agent and thread\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import AzureAISearchTool, ConnectionType\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "\n",
    "from semantic_kernel.agents.azure_ai import AzureAIAgent, AzureAIAgentSettings\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# For this demo, we will use the same index name as before\n",
    "AZURE_AI_SEARCH_INDEX_NAME = \"myfitnessindex\"\n",
    "\n",
    "# Get required environment variables\n",
    "model_deployment_name = loaded_config.get(\"MODEL_DEPLOYMENT_NAME\")\n",
    "project_connection_string = loaded_config.get(\"PROJECT_CONNECTION_STRING\")\n",
    "\n",
    "if not model_deployment_name:\n",
    "    raise ValueError(\"🚨 MODEL_DEPLOYMENT_NAME not set in .env\")\n",
    "if not project_connection_string:\n",
    "    raise ValueError(\"🚨 PROJECT_CONNECTION_STRING not set in .env\")\n",
    "\n",
    "# Create agent settings with required parameters\n",
    "ai_agent_settings = AzureAIAgentSettings.create(\n",
    "    model_deployment_name=model_deployment_name,\n",
    "    project_connection_string=project_connection_string\n",
    ")\n",
    "\n",
    "async with (\n",
    "    DefaultAzureCredential() as creds,\n",
    "    AIProjectClient.from_connection_string(\n",
    "        credential=creds,\n",
    "        conn_str=ai_agent_settings.project_connection_string.get_secret_value()\n",
    "    ) as client,\n",
    "):\n",
    "    # List available connections and find one of type Azure AI Search\n",
    "    conn_list = await client.connections.list()\n",
    "    ai_search_conn_id = \"\"\n",
    "    for conn in conn_list:\n",
    "        if conn.connection_type == ConnectionType.AZURE_AI_SEARCH:\n",
    "            ai_search_conn_id = conn.id\n",
    "            break\n",
    "\n",
    "    if not ai_search_conn_id:\n",
    "        print(\"❌ No Azure AI Search connection found.\")\n",
    "        raise ValueError(\"❌ No Azure AI Search connection found.\")\n",
    "\n",
    "    # Create the Azure AI Search tool pointing to our fitness index\n",
    "    ai_search_tool = AzureAISearchTool(\n",
    "        index_connection_id=ai_search_conn_id, \n",
    "        index_name=AZURE_AI_SEARCH_INDEX_NAME\n",
    "    )\n",
    "\n",
    "    # Create the agent definition with instructions for a fitness shopping assistant\n",
    "    agent_definition = await client.agents.create_agent(\n",
    "        model=ai_agent_settings.model_deployment_name,\n",
    "        instructions=\"\"\"\n",
    "            You are a Fitness Shopping Assistant. You help users find fitness equipment based on their queries.\n",
    "            Always include a disclaimer that you are not providing medical advice.\n",
    "        \"\"\",\n",
    "        tools=ai_search_tool.definitions,\n",
    "        tool_resources=ai_search_tool.resources,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "    )\n",
    "\n",
    "    # Create the Semantic Kernel Azure AI Agent\n",
    "    agent = AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=agent_definition,\n",
    "    )\n",
    "\n",
    "    # Create a new conversation thread\n",
    "    thread = await client.agents.create_thread()\n",
    "    print(f\"📝 Created thread with ID: {thread.id}\")\n",
    "\n",
    "    # Define some example fitness queries\n",
    "    user_queries = [\n",
    "        \"Which items are best for strength training?\",\n",
    "        \"I need something for cardio under $300. Any suggestions?\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        for query in user_queries:\n",
    "            # Add the user message\n",
    "            await agent.add_chat_message(\n",
    "                thread_id=thread.id,\n",
    "                message=ChatMessageContent(role=AuthorRole.USER, content=query),\n",
    "            )\n",
    "            print(f\"\\n# User: {query}\\n\")\n",
    "\n",
    "            # Invoke the agent and stream its response\n",
    "            async for content in agent.invoke(thread_id=thread.id):\n",
    "                if content.role != AuthorRole.TOOL:\n",
    "                    print(f\"# Agent: {content.content}\\n\")\n",
    "    finally:\n",
    "        # Clean up the conversation thread and agent\n",
    "        await client.agents.delete_thread(thread.id)\n",
    "        await client.agents.delete_agent(agent.id)\n",
    "        print(\"🗑️ Cleaned up agent and thread\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-md",
   "metadata": {},
   "source": [
    "## 3. Cleanup\n",
    "\n",
    "For this demo we already clean up the agent and thread inside the async function. In case you want to remove the search index as well (for a fresh start), run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cleanup-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Deleted index myfitnessindex\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    index_client.delete_index(index_name)\n",
    "    print(f\"🗑️ Deleted index {index_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congrats-md",
   "metadata": {},
   "source": [
    "# 🎉 Congrats!\n",
    "\n",
    "You've successfully:\n",
    "\n",
    "1. Created an Azure AI Search index and populated it with fitness data\n",
    "2. Verified the data via a basic search query\n",
    "3. Built and run a Semantic Kernel Agent that leverages Azure AI Search to answer natural language queries\n",
    "\n",
    "Feel free to explore further enhancements (e.g. integrating more tools or advanced evaluation) and enjoy your journey with Azure AI Foundry and Semantic Kernel!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
